{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torchvision.io import read_image\nfrom torchvision import transforms\nimport torch\nimport os\nimport csv\n\n\nclass ISICDataset(Dataset):\n    def __init__(self, img_dir, labels_dir):\n        file = open(labels_dir, \"r\")\n        csv_reader = csv.reader(file)\n\n        self.img_labels = []\n        for row in csv_reader:\n            self.img_labels.append(row)\n        \n        self.img_dir = img_dir\n        self.transform = transforms.Compose([\n                        transforms.Resize((224,224)), \n                        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n                                             ])\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels[idx][0])\n        image = self.transform(read_image(img_path)/255)\n        label = torch.Tensor([1 if self.img_labels[idx][1:].count(str(i))\n                                else 0 for i in range(5)])\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:41:58.547542Z","iopub.execute_input":"2021-08-11T07:41:58.547914Z","iopub.status.idle":"2021-08-11T07:41:59.843055Z","shell.execute_reply.started":"2021-08-11T07:41:58.547828Z","shell.execute_reply":"2021-08-11T07:41:59.842258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindir = '../input/isic-2018/ISIC2018_Task1-2_Training_Input/ISIC2018_Task1-2_Training_Input'\ntrain_labels_dir = '../input/isic-2018/train_labels.csv'\nvaliddir = '../input/isic-2018/ISIC2018_Task1-2_Validation_Input/ISIC2018_Task1-2_Validation_Input'\nvalid_labels_dir = '../input/isic-2018/valid_labels.csv'","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:42:09.51867Z","iopub.execute_input":"2021-08-11T07:42:09.519019Z","iopub.status.idle":"2021-08-11T07:42:09.524009Z","shell.execute_reply.started":"2021-08-11T07:42:09.518985Z","shell.execute_reply":"2021-08-11T07:42:09.522715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import random_split, DataLoader\n\ndata = ISICDataset(traindir, train_labels_dir)\ntrain_dl = DataLoader(data, batch_size = 32, shuffle = True, pin_memory = True)\n\nvalid_data = ISICDataset(validdir, valid_labels_dir)\nvalid_dl = DataLoader(valid_data, batch_size = 10)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:42:14.859727Z","iopub.execute_input":"2021-08-11T07:42:14.860047Z","iopub.status.idle":"2021-08-11T07:42:14.893525Z","shell.execute_reply.started":"2021-08-11T07:42:14.860015Z","shell.execute_reply":"2021-08-11T07:42:14.892731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\nimport torch\nmodel = torchvision.models.resnet34(pretrained = True)\nmodel.fc = torch.nn.Sequential(\n            torch.nn.Linear(in_features = 512, out_features = 4, bias = True),\n            torch.nn.Sigmoid())","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:42:39.570514Z","iopub.execute_input":"2021-08-11T07:42:39.570862Z","iopub.status.idle":"2021-08-11T07:42:44.056339Z","shell.execute_reply.started":"2021-08-11T07:42:39.570828Z","shell.execute_reply":"2021-08-11T07:42:44.055456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.cuda()\nmodel.load_state_dict(torch.load('../input/my-models/best_model rot.pt'))\nmodel.fc = torch.nn.Sequential(\n            torch.nn.Linear(in_features = 512, out_features = 5, bias = True),\n            torch.nn.Sigmoid())","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:43:35.30668Z","iopub.execute_input":"2021-08-11T07:43:35.307003Z","iopub.status.idle":"2021-08-11T07:43:41.985759Z","shell.execute_reply.started":"2021-08-11T07:43:35.306973Z","shell.execute_reply":"2021-08-11T07:43:41.984889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.init(project='ISIC2018', entity='tro2vs')\nconfig = wandb.config\nconfig.learning_rate = 0.001\nwandb.watch(model)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:43:47.231944Z","iopub.execute_input":"2021-08-11T07:43:47.232284Z","iopub.status.idle":"2021-08-11T07:45:43.094016Z","shell.execute_reply.started":"2021-08-11T07:43:47.232243Z","shell.execute_reply":"2021-08-11T07:45:43.09316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nimport time\n\ndef norm_pred(pred):\n    return pred > 0.5\n\ndef acc(labels, pred):\n    return sum((labels == norm_pred(pred)).view(-1)).cpu().detach().numpy()/len(labels.view(-1))\n\ndef train(model, train_dl, valid_dl, loss_fn, optimizer, epochs=1):\n    start = time.time()\n    model.cuda()\n    best_acc = 0\n    \n    for epoch in range(epochs):\n        print('Epoch {}/{}'.format(epoch, epochs - 1))\n        print('-' * 10)\n\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train(True)  \n                dataloader = train_dl\n            else:\n                model.train(False)\n                dataloader = valid_dl\n\n            running_loss = 0.0\n            running_acc = 0.0\n\n            step = 0\n            \n            for x, y in dataloader:\n                x = x.cuda()\n                y = y.cuda()\n                step += 1\n\n                if phase == 'train':\n                    optimizer.zero_grad()\n                    outputs = model(x)\n                    loss = loss_fn(outputs, y)\n\n                    loss.backward()\n                    optimizer.step()\n\n                else:\n                    with torch.no_grad():\n                        outputs = model(x)\n                        loss = loss_fn(outputs, y)\n\n                running_acc  += acc(y, outputs)*dataloader.batch_size\n                running_loss += loss*dataloader.batch_size\n\n                if step % 10 == 0:\n                    print('Current step: {}  Loss: {}  Acc: {}  AllocMem (Mb): {}'.format(step, loss, acc(y, outputs), torch.cuda.memory_allocated()/1024/1024))\n                \n          \n                \n            epoch_loss = running_loss / len(dataloader.dataset)\n            epoch_acc = running_acc / len(dataloader.dataset)\n            \n            f1 = f1_score(y.cpu().detach().numpy(),\n                                            norm_pred(outputs).cpu().detach().numpy(),\n                                  average = None, labels=[0,1,2,3,4])\n            f1_mic = f1_score(y.cpu().detach().numpy(),\n                                            norm_pred(outputs).cpu().detach().numpy(),\n                                  average = 'micro', labels=[0,1,2,3,4])\n            f1_mac = f1_score(y.cpu().detach().numpy(),\n                                            norm_pred(outputs).cpu().detach().numpy(),\n                                  average = 'macro', labels=[0,1,2,3,4])\n            f1_weighted = f1_score(y.cpu().detach().numpy(),\n                                            norm_pred(outputs).cpu().detach().numpy(),\n                                  average = 'weighted', labels=[0,1,2,3,4])\n            \n            print('{} Loss: {:.4f} Acc: {}'.format(phase, epoch_loss, epoch_acc))\n            \n            if phase == 'valid':\n                wandb.log({\"Loss/test\": epoch_loss})\n                wandb.log({\"Accuracy/test\": epoch_acc})\n                wandb.log({\"f1-score/test/micro\": f1_mic})\n                wandb.log({\"f1-score/test/macro\": f1_mac})\n                wandb.log({\"f1-score/test/weighted\": f1_weighted})\n\n                for i in range(5):\n                    wandb.log({\"f1-score/test/class_\"+str(i): f1[i]})      \n                \n                if epoch_acc > best_acc:\n                    best_acc = epoch_acc\n                    torch.save(model.state_dict(), \"best_model.pt\")\n                    wandb.save('./best_model.pt')\n            else:\n                torch.save(model.state_dict(), \"full_train_model.pt\")\n                wandb.save('./full_train_model.pt')\n                \n                wandb.log({\"Loss/train\": epoch_loss})\n                wandb.log({\"Accuracy/train\": epoch_acc})\n                wandb.log({\"f1-score/train/micro\": f1_mic})\n                wandb.log({\"f1-score/train/macro\": f1_mac})\n                wandb.log({\"f1-score/train/weighted\": f1_weighted})\n                \n                for i in range(5):\n                    wandb.log({\"f1-score/train/class_\"+str(i): f1[i]})\n                \n\n\n    time_elapsed = time.time() - start\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n    #model = torch.load(\"best_model.pt\")","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:45:49.479215Z","iopub.execute_input":"2021-08-11T07:45:49.479556Z","iopub.status.idle":"2021-08-11T07:45:49.500803Z","shell.execute_reply.started":"2021-08-11T07:45:49.479526Z","shell.execute_reply":"2021-08-11T07:45:49.499844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nclass JacLoss(torch.nn.Module):\n    def __init__(self, weight=None, size_average=True, threshold = 0):\n        super(JacLoss, self).__init__()\n        self.th = threshold\n\n    def forward(self, inputs, targets, smooth=1e-6):\n        \n        #inputs = inputs.view(-1)\n        #targets = targets.view(-1)\n        \n        intersection = (inputs * targets).sum(dim = 1)\n        total = (inputs + targets).sum(dim = 1)\n        union = total - intersection \n        \n        IoU = intersection/(union + smooth)\n        IoU = torch.mean(torch.cat((IoU[IoU > self.th], \n                                    torch.Tensor([0 for i in range((IoU <= self.th).sum())]).cuda())))\n\n        return 1 - IoU","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:45:54.048985Z","iopub.execute_input":"2021-08-11T07:45:54.049337Z","iopub.status.idle":"2021-08-11T07:45:54.059037Z","shell.execute_reply.started":"2021-08-11T07:45:54.049305Z","shell.execute_reply":"2021-08-11T07:45:54.058178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Class elements: [603, 682, 190, 1523, 100]. None: 514","metadata":{}},{"cell_type":"code","source":"loss_fn = torch.nn.BCELoss(weight = torch.Tensor([2.526, 2.23, 8.016, 1, 15.23]).cuda())\n#loss_fn = JacLoss(threshold = 0.35)\nopt = torch.optim.Adam(model.parameters(), lr = 0.001)\ntrain(model, train_dl, valid_dl, loss_fn, \n                             opt, epochs = 5)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T07:46:09.336826Z","iopub.execute_input":"2021-08-11T07:46:09.337163Z","iopub.status.idle":"2021-08-11T08:07:47.353249Z","shell.execute_reply.started":"2021-08-11T07:46:09.337117Z","shell.execute_reply":"2021-08-11T08:07:47.347167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:31:06.049973Z","iopub.execute_input":"2021-08-10T17:31:06.0504Z","iopub.status.idle":"2021-08-10T17:31:10.201406Z","shell.execute_reply.started":"2021-08-10T17:31:06.050364Z","shell.execute_reply":"2021-08-10T17:31:10.200425Z"},"trusted":true},"execution_count":null,"outputs":[]}]}